{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.6292\n",
      "Epoch [20/200], Loss: 0.7478\n",
      "Epoch [30/200], Loss: 0.5577\n",
      "Epoch [40/200], Loss: 0.6789\n",
      "Epoch [50/200], Loss: 0.7333\n",
      "Epoch [60/200], Loss: 0.7574\n",
      "Epoch [70/200], Loss: 0.6911\n",
      "Epoch [80/200], Loss: 0.5722\n",
      "Epoch [90/200], Loss: 0.6532\n",
      "Epoch [100/200], Loss: 0.5701\n",
      "Epoch [110/200], Loss: 0.6660\n",
      "Epoch [120/200], Loss: 0.5701\n",
      "Epoch [130/200], Loss: 0.5010\n",
      "Epoch [140/200], Loss: 0.5854\n",
      "Epoch [150/200], Loss: 0.6439\n",
      "Epoch [160/200], Loss: 0.5091\n",
      "Epoch [170/200], Loss: 0.7048\n",
      "Epoch [180/200], Loss: 0.2048\n",
      "Epoch [190/200], Loss: 0.5441\n",
      "Epoch [200/200], Loss: 0.3174\n",
      "Train Accuracy: 0.6651, Precision: 0.6391, Recall: 0.8381, F1: 0.7252\n",
      "Test Accuracy: 0.5137, Precision: 0.5076, Recall: 0.5583, F1: 0.5317\n",
      "Validation Accuracy: 0.4558, Precision: 0.5068, Recall: 0.4568, F1: 0.4805\n",
      "Validation results saved to 'validation_predictions_lstm.csv'\n",
      "Model saved to 'lstm_model.pth'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터베이스 파일 경로\n",
    "db_file = '../btc_data_day_20170901_20241205.db'\n",
    "\n",
    "# 데이터베이스 연결\n",
    "con = sqlite3.connect(db_file)\n",
    "\n",
    "# SQL 쿼리 실행 및 데이터프레임으로 불러오기\n",
    "query = \"SELECT * FROM ticker_data\"\n",
    "df = pd.read_sql_query(query, con)\n",
    "\n",
    "# 데이터베이스 연결 종료\n",
    "con.close()\n",
    "\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df['datetime'] = pd.to_datetime(df['trade_date'] + ' ' + df['trade_time'])\n",
    "df = df.sort_values(by='datetime')\n",
    "df.rename(columns={'trade_price':'closing_price'}, inplace=True)\n",
    "new_column_order = [\n",
    "    'datetime', 'type', 'code', 'opening_price', 'closing_price', 'high_price', 'low_price', 'trade_volume', 'trade_date'\n",
    "]\n",
    "df = df[new_column_order] \n",
    "df = df[df['trade_date']!='2017-09-26']\n",
    "df = df[df['trade_date']!='2017-09-25']\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 3.1 이동 평균 (5일 WMA)\n",
    "def calculate_wma(data, period=5):\n",
    "    weights = np.arange(1, period + 1)\n",
    "    def wma(prices):\n",
    "        return np.dot(prices, weights) / weights.sum()\n",
    "    return data['closing_price'].rolling(period).apply(wma, raw=True)\n",
    "\n",
    "df['wma_5'] = calculate_wma(df)\n",
    "\n",
    "# 3.2 볼린저 밴드\n",
    "def calculate_bollinger_bands(data, period=10):\n",
    "    # 중간 밴드 (10일 SMA)\n",
    "    data['middle_band'] = data['closing_price'].rolling(period).mean()\n",
    "    \n",
    "    # 표준편차 계산\n",
    "    data['std'] = data['closing_price'].rolling(period).std()\n",
    "    \n",
    "    # 상단 밴드 및 하단 밴드 계산\n",
    "    data['upper_band'] = data['middle_band'] + 2 * data['std']\n",
    "    data['lower_band'] = data['middle_band'] - 2 * data['std']\n",
    "    \n",
    "    # %B 계산\n",
    "    data['%B'] = (data['closing_price'] - data['lower_band']) / (data['upper_band'] - data['lower_band'])\n",
    "    \n",
    "    # 대역폭(BW) 계산\n",
    "    data['bandwidth'] = (data['upper_band'] - data['lower_band']) / data['middle_band']\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = calculate_bollinger_bands(df)\n",
    "\n",
    "\n",
    "# 3.3 RSI\n",
    "def calculate_rsi(data, period=9):\n",
    "    delta = data['closing_price'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=1).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    rsi = rsi.replace([np.inf, -np.inf], np.nan) # inf 값을 nan 값으로 바꿈\n",
    "    return rsi\n",
    "\n",
    "df['rsi_9'] = calculate_rsi(df)\n",
    "\n",
    "# 3.4 MACD\n",
    "def calculate_macd(data, short_period=12, long_period=26, signal_period=9):\n",
    "    # EMA 계산\n",
    "    ema_short = data['closing_price'].ewm(span=short_period, adjust=False).mean()\n",
    "    ema_long = data['closing_price'].ewm(span=long_period, adjust=False).mean()\n",
    "\n",
    "    # MACD 계산\n",
    "    macd = ema_short - ema_long\n",
    "\n",
    "    # MACD 신호 계산\n",
    "    signal = macd.ewm(span=signal_period, adjust=False).mean()\n",
    "    \n",
    "    return macd, signal\n",
    "\n",
    "macd, signal = calculate_macd(df)\n",
    "df['macd'] = macd\n",
    "df['macd_signal'] = signal\n",
    "\n",
    "# 3.5 Stochastic Oscillator\n",
    "def calculate_stochastic_oscillator(data, period=5, d_period=3):\n",
    "    # 최고가와 최저가 계산\n",
    "    data['highest_5'] = data['high_price'].rolling(window=period).max()\n",
    "    data['lowest_5'] = data['low_price'].rolling(window=period).min()\n",
    "\n",
    "    # %K 계산\n",
    "    data['%K'] = ((data['closing_price'] - data['lowest_5']) / (data['highest_5'] - data['lowest_5'])) * 100\n",
    "\n",
    "    # %D 계산\n",
    "    data['%D'] = data['%K'].rolling(window=d_period).mean()\n",
    "    \n",
    "    data['%K'] = data['%K'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = calculate_stochastic_oscillator(df)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 출력 변수 생성\n",
    "df['price_change'] = df['closing_price'].diff()\n",
    "df['output'] = (df['price_change'] > 0).astype(int)\n",
    "df.drop(columns=['price_change'], inplace=True)\n",
    "\n",
    "# 입력 변수 선택\n",
    "input_features = [\n",
    "    'opening_price', 'high_price', 'low_price', 'closing_price',\n",
    "    'wma_5', 'middle_band', 'upper_band', 'lower_band', '%B', 'bandwidth',\n",
    "    'rsi_9', 'macd', 'macd_signal', '%K', '%D'\n",
    "]\n",
    "\n",
    "# 데이터셋 분할\n",
    "train_end_date = pd.to_datetime('2024-06-30')\n",
    "validation_start_date = pd.to_datetime('2024-07-01')\n",
    "\n",
    "# 훈련 데이터 및 테스트 데이터 분할 (2024년 6월 30일 이전 데이터)\n",
    "train_df = df[df['datetime'] <= train_end_date]\n",
    "train_size = int(len(train_df) * 0.7)  # 7:3 비율\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "X_train = train_df[input_features][:train_size].values\n",
    "y_train = train_df['output'][:train_size].values\n",
    "X_test = train_df[input_features][train_size:].values\n",
    "y_test = train_df['output'][train_size:].values\n",
    "\n",
    "\n",
    "# 검증 데이터 분할 (2024년 7월 1일 이후 데이터)\n",
    "validation_df = df[(df['datetime'] >= validation_start_date) & (df['datetime'] <= df['datetime'].max())]\n",
    "X_validation = validation_df[input_features].values\n",
    "y_validation = validation_df['output'].values\n",
    "validation_dates = validation_df['datetime'].values\n",
    "\n",
    "# 데이터 정규화 (Min-Max Scaling)\n",
    "def min_max_scaling(data):\n",
    "    min_vals = np.min(data, axis=0)\n",
    "    max_vals = np.max(data, axis=0)\n",
    "    scaled_data = (data - min_vals) / (max_vals - min_vals)\n",
    "    return scaled_data,min_vals, max_vals\n",
    "\n",
    "X_train_scaled,min_vals_train, max_vals_train= min_max_scaling(X_train)\n",
    "X_test_scaled,min_vals_test,max_vals_test = min_max_scaling(X_test)\n",
    "X_validation_scaled,min_vals_val,max_vals_val = min_max_scaling(X_validation)\n",
    "\n",
    "# ----------------------------\n",
    "# LSTM-RNN 모델 정의\n",
    "# ----------------------------\n",
    "class LSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=60, sequence_length=10):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 2) # 이진 분류를 위한 출력 크기 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length, input_size]\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device) # hidden state 초기화\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # cell state 초기화\n",
    "        out, _ = self.lstm(x, (h0, c0)) # LSTM 레이어 통과\n",
    "        out = self.fc(out[:, -1, :]) # 최종 hidden state만 사용\n",
    "        return out\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = len(input_features)\n",
    "hidden_size = 60\n",
    "sequence_length = 10  # sequence length\n",
    "batch_size = 10\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능하면 GPU 사용, 아니면 CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 시퀀스 데이터 변환 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length), :-1]\n",
    "        y = data[i + seq_length, -1]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 시퀀스 데이터 생성 및 로더\n",
    "X_train_seq, y_train_seq = create_sequences(np.hstack((X_train_scaled, y_train.reshape(-1, 1))), sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(np.hstack((X_test_scaled, y_test.reshape(-1, 1))), sequence_length)\n",
    "X_val_seq, y_val_seq = create_sequences(np.hstack((X_validation_scaled, y_validation.reshape(-1, 1))), sequence_length)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train_seq).to(device), torch.LongTensor(y_train_seq).to(device))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(X_test_seq).to(device), torch.LongTensor(y_test_seq).to(device))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val_seq).to(device), torch.LongTensor(y_val_seq).to(device))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 정의\n",
    "model = LSTM_RNN(input_size, hidden_size, sequence_length).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0 :\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    precision = precision_score(actual_labels, predictions, average='binary', zero_division=0)\n",
    "    recall = recall_score(actual_labels, predictions, average='binary', zero_division=0)\n",
    "    f1 = f1_score(actual_labels, predictions, average='binary', zero_division=0)\n",
    "    return accuracy, precision, recall, f1, predictions, actual_labels\n",
    "\n",
    "# 모델 성능 평가 및 검증 데이터 예측 결과 저장\n",
    "train_accuracy, train_precision, train_recall, train_f1,_,_ = evaluate_model(model, train_loader)\n",
    "test_accuracy, test_precision, test_recall, test_f1,_,_ = evaluate_model(model, test_loader)\n",
    "val_accuracy, val_precision, val_recall, val_f1, val_predictions, val_actual_labels = evaluate_model(model, val_loader)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "# 검증 데이터 예측 결과 저장\n",
    "val_results = pd.DataFrame({'datetime':validation_dates[sequence_length:], 'Actual': val_actual_labels, 'Predicted': val_predictions})\n",
    "val_results['datetime'] = pd.to_datetime(val_results['datetime'])\n",
    "val_results['datetime'] = val_results['datetime'].dt.strftime('%Y-%m-%d')\n",
    "val_results.to_csv('validation_predictions_lstm.csv', index=False)\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'lstm_model.pth')\n",
    "\n",
    "print(f\"Validation results saved to 'validation_predictions_lstm.csv'\")\n",
    "print(f\"Model saved to 'lstm_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.6902\n",
      "Epoch [20/200], Loss: 0.6815\n",
      "Epoch [30/200], Loss: 0.6909\n",
      "Epoch [40/200], Loss: 0.6870\n",
      "Epoch [50/200], Loss: 0.6964\n",
      "Epoch [60/200], Loss: 0.6740\n",
      "Epoch [70/200], Loss: 0.6992\n",
      "Epoch [80/200], Loss: 0.6742\n",
      "Epoch [90/200], Loss: 0.6909\n",
      "Epoch [100/200], Loss: 0.6914\n",
      "Epoch [110/200], Loss: 0.6824\n",
      "Epoch [120/200], Loss: 0.6972\n",
      "Epoch [130/200], Loss: 0.7087\n",
      "Epoch [140/200], Loss: 0.6806\n",
      "Epoch [150/200], Loss: 0.6784\n",
      "Epoch [160/200], Loss: 0.6986\n",
      "Epoch [170/200], Loss: 0.7027\n",
      "Epoch [180/200], Loss: 0.6945\n",
      "Epoch [190/200], Loss: 0.6848\n",
      "Epoch [200/200], Loss: 0.7104\n",
      "Train Accuracy: 0.5272, Precision: 0.5272, Recall: 1.0000, F1: 0.6904\n",
      "Test Accuracy: 0.4945, Precision: 0.4945, Recall: 1.0000, F1: 0.6618\n",
      "Validation Accuracy: 0.5510, Precision: 0.5510, Recall: 1.0000, F1: 0.7105\n",
      "Validation results saved to 'validation_predictions_lstm_4layers.csv'\n",
      "Model saved to 'lstm_model_4layers.pth'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터베이스 파일 경로\n",
    "db_file = '../btc_data_day_20170901_20241205.db'\n",
    "\n",
    "# 데이터베이스 연결\n",
    "con = sqlite3.connect(db_file)\n",
    "\n",
    "# SQL 쿼리 실행 및 데이터프레임으로 불러오기\n",
    "query = \"SELECT * FROM ticker_data\"\n",
    "df = pd.read_sql_query(query, con)\n",
    "\n",
    "# 데이터베이스 연결 종료\n",
    "con.close()\n",
    "\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df['datetime'] = pd.to_datetime(df['trade_date'] + ' ' + df['trade_time'])\n",
    "df = df.sort_values(by='datetime')\n",
    "df.rename(columns={'trade_price':'closing_price'}, inplace=True)\n",
    "new_column_order = [\n",
    "    'datetime', 'type', 'code', 'opening_price', 'closing_price', 'high_price', 'low_price', 'trade_volume', 'trade_date'\n",
    "]\n",
    "df = df[new_column_order] \n",
    "df = df[df['trade_date']!='2017-09-26']\n",
    "df = df[df['trade_date']!='2017-09-25']\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 3.1 이동 평균 (5일 WMA)\n",
    "def calculate_wma(data, period=5):\n",
    "    weights = np.arange(1, period + 1)\n",
    "    def wma(prices):\n",
    "        return np.dot(prices, weights) / weights.sum()\n",
    "    return data['closing_price'].rolling(period).apply(wma, raw=True)\n",
    "\n",
    "df['wma_5'] = calculate_wma(df)\n",
    "\n",
    "# 3.2 볼린저 밴드\n",
    "def calculate_bollinger_bands(data, period=10):\n",
    "    # 중간 밴드 (10일 SMA)\n",
    "    data['middle_band'] = data['closing_price'].rolling(period).mean()\n",
    "    \n",
    "    # 표준편차 계산\n",
    "    data['std'] = data['closing_price'].rolling(period).std()\n",
    "    \n",
    "    # 상단 밴드 및 하단 밴드 계산\n",
    "    data['upper_band'] = data['middle_band'] + 2 * data['std']\n",
    "    data['lower_band'] = data['middle_band'] - 2 * data['std']\n",
    "    \n",
    "    # %B 계산\n",
    "    data['%B'] = (data['closing_price'] - data['lower_band']) / (data['upper_band'] - data['lower_band'])\n",
    "    \n",
    "    # 대역폭(BW) 계산\n",
    "    data['bandwidth'] = (data['upper_band'] - data['lower_band']) / data['middle_band']\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = calculate_bollinger_bands(df)\n",
    "\n",
    "\n",
    "# 3.3 RSI\n",
    "def calculate_rsi(data, period=9):\n",
    "    delta = data['closing_price'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=period, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=1).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    rsi = rsi.replace([np.inf, -np.inf], np.nan) # inf 값을 nan 값으로 바꿈\n",
    "    return rsi\n",
    "\n",
    "df['rsi_9'] = calculate_rsi(df)\n",
    "\n",
    "# 3.4 MACD\n",
    "def calculate_macd(data, short_period=12, long_period=26, signal_period=9):\n",
    "    # EMA 계산\n",
    "    ema_short = data['closing_price'].ewm(span=short_period, adjust=False).mean()\n",
    "    ema_long = data['closing_price'].ewm(span=long_period, adjust=False).mean()\n",
    "\n",
    "    # MACD 계산\n",
    "    macd = ema_short - ema_long\n",
    "\n",
    "    # MACD 신호 계산\n",
    "    signal = macd.ewm(span=signal_period, adjust=False).mean()\n",
    "    \n",
    "    return macd, signal\n",
    "\n",
    "macd, signal = calculate_macd(df)\n",
    "df['macd'] = macd\n",
    "df['macd_signal'] = signal\n",
    "\n",
    "# 3.5 Stochastic Oscillator\n",
    "def calculate_stochastic_oscillator(data, period=5, d_period=3):\n",
    "    # 최고가와 최저가 계산\n",
    "    data['highest_5'] = data['high_price'].rolling(window=period).max()\n",
    "    data['lowest_5'] = data['low_price'].rolling(window=period).min()\n",
    "\n",
    "    # %K 계산\n",
    "    data['%K'] = ((data['closing_price'] - data['lowest_5']) / (data['highest_5'] - data['lowest_5'])) * 100\n",
    "\n",
    "    # %D 계산\n",
    "    data['%D'] = data['%K'].rolling(window=d_period).mean()\n",
    "    \n",
    "    data['%K'] = data['%K'].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = calculate_stochastic_oscillator(df)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 출력 변수 생성\n",
    "df['price_change'] = df['closing_price'].diff()\n",
    "df['output'] = (df['price_change'] > 0).astype(int)\n",
    "df.drop(columns=['price_change'], inplace=True)\n",
    "\n",
    "# 입력 변수 선택\n",
    "input_features = [\n",
    "    'opening_price', 'high_price', 'low_price', 'closing_price',\n",
    "    'wma_5', 'middle_band', 'upper_band', 'lower_band', '%B', 'bandwidth',\n",
    "    'rsi_9', 'macd', 'macd_signal', '%K', '%D'\n",
    "]\n",
    "\n",
    "# 데이터셋 분할\n",
    "train_end_date = pd.to_datetime('2024-06-30')\n",
    "validation_start_date = pd.to_datetime('2024-07-01')\n",
    "\n",
    "# 훈련 데이터 및 테스트 데이터 분할 (2024년 6월 30일 이전 데이터)\n",
    "train_df = df[df['datetime'] <= train_end_date]\n",
    "train_size = int(len(train_df) * 0.7)  # 7:3 비율\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "X_train = train_df[input_features][:train_size].values\n",
    "y_train = train_df['output'][:train_size].values\n",
    "X_test = train_df[input_features][train_size:].values\n",
    "y_test = train_df['output'][train_size:].values\n",
    "\n",
    "\n",
    "# 검증 데이터 분할 (2024년 7월 1일 이후 데이터)\n",
    "validation_df = df[(df['datetime'] >= validation_start_date) & (df['datetime'] <= df['datetime'].max())]\n",
    "X_validation = validation_df[input_features].values\n",
    "y_validation = validation_df['output'].values\n",
    "validation_dates = validation_df['datetime'].values\n",
    "\n",
    "# 데이터 정규화 (Min-Max Scaling)\n",
    "def min_max_scaling(data):\n",
    "    min_vals = np.min(data, axis=0)\n",
    "    max_vals = np.max(data, axis=0)\n",
    "    scaled_data = (data - min_vals) / (max_vals - min_vals)\n",
    "    return scaled_data,min_vals, max_vals\n",
    "\n",
    "X_train_scaled,min_vals_train, max_vals_train= min_max_scaling(X_train)\n",
    "X_test_scaled,min_vals_test,max_vals_test = min_max_scaling(X_test)\n",
    "X_validation_scaled,min_vals_val,max_vals_val = min_max_scaling(X_validation)\n",
    "\n",
    "# ----------------------------\n",
    "# LSTM-RNN 모델 정의 (4개 LSTM 층)\n",
    "# ----------------------------\n",
    "class LSTM_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=60, sequence_length=10, dropout_rate=0.2):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=False)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=False)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=False)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.lstm4 = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=False)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 2) # 완전 연결 레이어\n",
    "\n",
    "    def forward(self, x):\n",
    "         # x: [batch_size, seq_length, input_size]\n",
    "        h0_1 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0_1 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm1(x, (h0_1, c0_1))\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        h0_2 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0_2 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm2(out, (h0_2, c0_2))\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        h0_3 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0_3 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm3(out, (h0_3, c0_3))\n",
    "        out = self.dropout3(out)\n",
    "\n",
    "        h0_4 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0_4 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm4(out, (h0_4, c0_4))\n",
    "        out = self.dropout4(out)\n",
    "        \n",
    "        out = self.fc(out[:, -1, :]) # 최종 hidden state만 사용\n",
    "        return out\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = len(input_features)\n",
    "hidden_size = 60\n",
    "sequence_length = 10\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능하면 GPU 사용, 아니면 CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 시퀀스 데이터 변환 함수\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length), :-1]\n",
    "        y = data[i + seq_length, -1]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# 시퀀스 데이터 생성 및 로더\n",
    "X_train_seq, y_train_seq = create_sequences(np.hstack((X_train_scaled, y_train.reshape(-1, 1))), sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences(np.hstack((X_test_scaled, y_test.reshape(-1, 1))), sequence_length)\n",
    "X_val_seq, y_val_seq = create_sequences(np.hstack((X_validation_scaled, y_validation.reshape(-1, 1))), sequence_length)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train_seq).to(device), torch.LongTensor(y_train_seq).to(device))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(X_test_seq).to(device), torch.LongTensor(y_test_seq).to(device))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val_seq).to(device), torch.LongTensor(y_val_seq).to(device))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 모델, 손실 함수, 옵티마이저 정의\n",
    "model = LSTM_RNN(input_size, hidden_size, sequence_length, dropout_rate).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0 :\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    precision = precision_score(actual_labels, predictions, average='binary', zero_division=0)\n",
    "    recall = recall_score(actual_labels, predictions, average='binary', zero_division=0)\n",
    "    f1 = f1_score(actual_labels, predictions, average='binary', zero_division=0)\n",
    "    return accuracy, precision, recall, f1, predictions, actual_labels\n",
    "\n",
    "# 모델 성능 평가 및 검증 데이터 예측 결과 저장\n",
    "train_accuracy, train_precision, train_recall, train_f1,_,_ = evaluate_model(model, train_loader)\n",
    "test_accuracy, test_precision, test_recall, test_f1,_,_ = evaluate_model(model, test_loader)\n",
    "val_accuracy, val_precision, val_recall, val_f1, val_predictions, val_actual_labels = evaluate_model(model, val_loader)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "# 검증 데이터 예측 결과 저장\n",
    "val_results = pd.DataFrame({'datetime':validation_dates[sequence_length:], 'Actual': val_actual_labels, 'Predicted': val_predictions})\n",
    "val_results['datetime'] = pd.to_datetime(val_results['datetime'])\n",
    "val_results['datetime'] = val_results['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S') # 시간까지 저장\n",
    "val_results.to_csv('validation_predictions_lstm_4layers.csv', index=False)\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'lstm_model_4layers.pth')\n",
    "\n",
    "print(f\"Validation results saved to 'validation_predictions_lstm_4layers.csv'\")\n",
    "print(f\"Model saved to 'lstm_model_4layers.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_CK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
